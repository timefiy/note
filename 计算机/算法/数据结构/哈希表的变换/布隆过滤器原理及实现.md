---
title: "布隆过滤器原理及实现"
source: "https://labuladong.online/zh/algo/data-structure-basic/bloom-filter/"
author:
  - "[[labuladong]]"
published:
created: 2026-02-06
description: "本文介绍布隆过滤器的原理，回答以下问题：什么是布隆过滤器；为什么它会有误判；如何选择哈希函数的个数和位数组的大小；布隆过滤器的应用场景。"
tags:
  - "clippings"
---
前置知识

阅读本文前，你需要先学习：

- [哈希表核心原理](https://labuladong.online/zh/algo/data-structure-basic/hashmap-basic/)
- [位图核心原理及实现](https://labuladong.online/zh/algo/data-structure-basic/bitmap/)

一句话总结

布隆过滤器的核心能力是：

- 在超大规模的数据集中，仅使用少量内存空间，即可快速判断一个元素是否存在。
- 具备数据隐私性。即，可以在不暴露具体数据的情况下，判断一个元素是否存在。

它的核心原理是，不存储具体数据，而仅仅存储数据指纹（哈希值），通过比对指纹来判断数据是否存在。

典型的超大规模数据场景有：

- 判断一个 HTTP 请求的 URL 是否在恶意 URL 列表中。这个列表的数量可以达到上亿，我们可以借助布隆过滤器，保证这个查询仅消耗少量的内存和查询时间，否则会影响用户体验。
- 在大数据存储系统中，海量的数据一般会分散存储在多个不同的文件中。查询一个数据时，需要在磁盘上遍历多个文件才能找到，效率很差。我们可以为每个文件在内存中维护一个布隆过滤器，以便快速判断目标数据是否存在于该文件中，避免无效的磁盘 IO 操作。

说到判断元素是否存在，首先应该想到前文讲的 [哈希集合](https://labuladong.online/zh/algo/data-structure-basic/hash-set/) ，它可以在 $O(1)$ 的时间增删元素，可以在 $O(1)$ 的时间判断一个元素是否存在。

但如果数据规模特别大，那就不行了。

因为哈希集合本质上就是哈希表，而在 [哈希表的代码实现](https://labuladong.online/zh/algo/data-structure-basic/hashtable-chaining/) 中，我们必须要用一个 `KVNode` 类把键值数据存储在内存中，以便处理哈希冲突。

所以哈希集合的空间复杂度是 $O(N)$ ，随着存储元素的数量增加，占用的内存也会线性增加。在超大数据规模场景下，有限的内存肯定是无法加载所有数据的。

同时，因为哈希集合要存储实际的数据，也就不具备数据隐私性。

那么，布隆过滤器是如何实现的呢？有了布隆过滤器，是否还需要哈希集合呢？

布隆过滤器的核心就是一个 [位图](https://labuladong.online/zh/algo/data-structure-basic/bitmap/) 和 $k$ 个不同的哈希函数。

当我们想往布隆过滤器中添加一个元素时，我们用 $k$ 个哈希函数对这个元素进行哈希计算，得到 $k$ 个不同的哈希值，这些哈希值就是位图的索引。然后我们把位图中的这几个索引对应的位都设置成 1。

当我们想判断一个元素是否存在于布隆过滤器时，我们也是用 $k$ 个哈希函数对这个元素进行哈希计算，得到 $k$ 个索引。

然后我们去看位图中的这 $k$ 个索引对应的位是否 **全部** 为 1。如果其中有一个位不为 1，那么这个元素 **一定不存在** 于集合中。如果这 $k$ 个位都为 1，那么这个元素 **可能存在** 于集合中。

为什么是 **可能存在** 呢？

因为随着布隆过滤器中存入的元素越来越多，位图中的这几个索引可能恰巧被其他元素设置成了 1，这就是所谓的 **假阳性误判** （false positive）。

下面，我们复用 [位图的原理与实现](https://labuladong.online/zh/algo/data-structure-basic/bitmap/) 中的 `MyBitSet` 类，来实现一个简化的布隆过滤器代码，展示其核心原理：

```
#include <iostream>

#include <string>

#include <cmath>

#include <functional>

using namespace std;

template<typename T>

class SimpleBloomFilter {

private:

    // 位图的大小

    int bitSetSize;

    // 位图

    MyBitSet* bitSet;

    // 哈希函数的个数

    int k;

    // 模拟多个哈希函数，实际生产环境中应该使用更复杂的哈希算法

    int hash(const T& element, int seed) {

        // 这里简化处理，用内置的 hash 函数和递增的索引作为种子来模拟多个哈希函数

        // 在实际应用中，为了减少哈希冲突，应该使用更复杂的哈希函数

        // 同时，种子也应该选择无规律的大质数，而不是简单的递增索引

        std::hash<T> hasher;

        size_t h = hasher(element);

        return abs(static_cast<int>(h) + seed) % bitSetSize;

    }

public:

    // 构造一个布隆过滤器，指定位图大小和哈希函数个数

    SimpleBloomFilter(int bitSetSize, int hashFunctionNum) 

        : bitSetSize(bitSetSize), k(hashFunctionNum) {

        bitSet = new MyBitSet(bitSetSize);

    }

    ~SimpleBloomFilter() {

        delete bitSet;

    }

    // 添加元素

    void add(const T& element) {

        // 获取 k 个不同的哈希值

        // 将这 k 个哈希值对应的位图中的位都设置为 1

        for (int i = 0; i < k; i++) {

            int hashValue = hash(element, i);

            bitSet->set(hashValue);

        }

    }

    // 判断元素是否存在

    bool contains(const T& element) {

        // 获取 k 个不同的哈希值

        // 检查这 k 个哈希值对应的位图中的位是否全部为 1

        for (int i = 0; i < k; i++) {

            int hashValue = hash(element, i);

            if (!bitSet->get(hashValue)) {

                return false;

            }

        }

        return true;

    }

};

int main() {

    // 创建一个位数组大小为 1000000，使用 3 个哈希函数的布隆过滤器

    SimpleBloomFilter<string> bloomFilter(1000000, 3);

    // 添加元素

    bloomFilter.add("apple");

    bloomFilter.add("banana");

    bloomFilter.add("orange");

    // 检查元素是否存在

    cout << "Contains apple: " << (bloomFilter.contains("apple") ? "true" : "false") << endl;       // true

    cout << "Contains banana: " << (bloomFilter.contains("banana") ? "true" : "false") << endl;     // true

    cout << "Contains grape: " << (bloomFilter.contains("grape") ? "true" : "false") << endl;       // false

    return 0;

}
```

这段代码实现了一个简化的布隆过滤器，但是其中还有很多地方可以进一步优化：

- **哈希函数过于简陋** ：示例代码中的 `hash` 函数通过 `element.hashCode() + seed` 的方式来模拟多个哈希函数，这种方式生成的哈希值分布不够均匀，会增加哈希冲突的概率，进而导致实际的误判率高于预期。在生产环境中，应该使用更可靠的哈希算法，例如 [MurmurHash](https://en.wikipedia.org/wiki/MurmurHash) 或 [FNV hash](https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function) 等。常用的技巧有两种：
	1. **双重哈希（Double Hashing）** ：使用两个高质量的哈希函数来模拟 $k$ 个哈希函数：
	$$
	hash(element, i) = (hash1(element) + i * hash2(element)) \mod bitSetSize
	$$
	1. **随机种子（Random Seeds）** ：预先生成 $k$ 个不同的随机种子（通常选择大的素数），然后用同一个哈希函数和这 $k$ 个种子计算出 $k$ 个不同的哈希值。这比示例代码中简单地使用递增索引 `0, 1, 2, ...` 作为种子要好得多，因为它能更好地模拟独立的哈希函数，进一步减少冲突。
- **缺少参数的自动优化** ：布隆过滤器的位图大小和哈希函数个数需要根据预估的数据量和可容忍的误判率来计算得出，这样才能最高效地利用内存。示例代码中这两个参数是写死的，这在实际应用中是不够灵活的。
	一个更健壮的实现应该提供一个构造函数，接收 `n` （预期插入的元素数量）和 `fpp` （可接受的误判率）作为参数，然后根据以下公式自动计算出最优的位图大小 `bitSetSize` 和哈希函数个数 `k` ：
	$$
	bitSetSize = -\frac{n \cdot \ln{(fpp)}}{(\ln{2})^2}
	$$
	 
	$$
	k = \frac{bitSetSize}{n} \cdot \ln{2}
	$$

## 布隆过滤器 vs 哈希集合

布隆过滤器和哈希集合都可以用来判断一个元素是否存在于一个集合中，但它们在实现原理、性能和适用场景上存在显著差异。

| 特性 | 布隆过滤器 | 哈希集合 |
| --- | --- | --- |
| **存储内容** | 只存储数据的「指纹」（哈希值），不存储数据本身。 | 存储数据本身，例如 `KVNode` 对象。 |
| **内存占用** | 极低，空间复杂度为 $O(bitSetSize)$ ，空间占用不随元素本身的大小变化。 | 较高，空间复杂度为 $O(N)$ ，其中 $N$ 是元素个数，并且与元素本身的大小有关。 |
| **查询结果** | 存在误判率（False Positive）：可能将不存在的元素判断为存在。 | 绝对精确，没有误判。 |
| **删除操作** | 标准的位图实现不支持删除。删除一个元素的位标记可能会影响其他元素。 | 支持删除操作。 |
| **数据隐私** | 具备数据隐私性，因为无法通过布隆过滤器反推出原始数据。 | 不具备数据隐私性，因为存储了原始数据。 |

**核心权衡点：**

布隆过滤器的核心是一种 **权衡（trade-off） **思想，它用** 较低的内存占用** 和 **一定的误判率** 换取了 **极高的查询效率** 。

如果你可以容忍误判率，那么布隆过滤器是一个非常高效的选择。

比如垃圾邮件过滤的场景，相比布隆过滤器来带的性能提升，偶尔把一个正常邮件误判为垃圾邮件是可以接受的。

再比如，对于开头讲的文件查询的场景，即便出现误判，代价只是多读取一个文件，如果误判率足够低，这种情况带来的性能损失是可以接受的。

更新时间：2026/02/05 12:53

## 评论

Markdown

Ctrl+Enter 发表