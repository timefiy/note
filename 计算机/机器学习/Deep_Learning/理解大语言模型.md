# 理解大语言模型

- LLM：大预言模型
	- 当我们说语言模型“理解”时，并不是说它们具有人类的意识或理解能力，而是指它们能够以看起来连贯且符合上下文的方式处理和生成文本。
	- 深度学习是机器学习和人工智能 (AI) 的一个子集，主要关注神经网络，LLM 可以基于深度学习理论在海量文本数据上进行训练
	- LLM 的成功可以归因于支撑 LLM 的 Transformer 架构，以及 LLM 训练所用的海量数据。
- NLP： 自然语言处理

## LLM是什么

LLM（大语言模型）是一个旨在理解、生成和响应人类文本的神经网络。这些模型是深度神经网络，在海量文本数据上训练，基本涵盖了互联网上大部分公开可用的文本数据集。
由于 LLM 能够生成文本，因此它们通常被称为一种生成式人工智能 (AI,GenAI)

![](assets/理解大语言模型/file-20260228202002665.png)

用于实现人工智能的==算法是机器学习领域的核心==.机器学习往往不需要明确的编程实现，而是涉及可以从数据中学习并基于数据做出预测或决策的算法研究
如图 1.1 所示，==深度学习是机器学习的一个子集==，专注于使用三层或更多层的神经网络（即深度神经网络）来建模数据中的复杂模式和抽象。与深度学习不同，传统机器学习需要手动提取特征。这意味着人类专家需要识别并选择最相关的特征供模型使用。
在传统机器学习中，人类专家会手动提取电子邮件文本中的特征，例如某些触发词的频率（“奖品”、“获胜”、“免费”）、感叹号的数量、全大写单词的使用，或者是否存在可疑链接。基于这些专家定义的特征创建的数据集随后用于训练模型。与传统机器学习不同，深度学习不需要手动提取特征，这意味着人类专家不需要为深度学习模型识别和选择最相关的特征。（不过，无论是在传统机器学习还是深度学习的垃圾邮件分类中，仍然需要收集标签，如垃圾邮件或非垃圾邮件，而这些标签需要由专家或用户进行收集。）

## LLM的应用
![](assets/理解大语言模型/file-20260228202748099.png)
LLM 被广泛用于机器翻译、新文本生成、情感分析、文本摘要等多种任务。
此外，LLM 还可以有效地从医学或法律等专业领域的大量文本中检索知识。这包括筛选文档、总结长段落以及回答技术性问题
总之，LLM 在自动化几乎所有涉及文本解析和生成的任务中都是不可或缺的。

## 构建和使用LLM的步骤
研究表明，在建模性能方面，专为特定任务或领域定制的 LLM 通常能超过通用的 LLM，比如 ChatGPT，这些通用模型设计用于多种应用场景。
创建 LLM 的一般过程包括**预训练**和**微调**。术语 "pre" 在 "pretraining"（预训练） 中指的是初始阶段，此时模型（如 LLM）在一个大型且多样化的数据集上进行训练，以便获得对语言的广泛理解。预训练模型随后作为基础资源，可以通过微调进一步优化。微调是指模型在一个更针对特定任务或领域的数据集上进行专门训练。[^1]![](assets/理解大语言模型/file-20260228203251056.png)
1. 创建 LLM 的第一步是用大量文本数据进行训练，这些数据一般被称为原始文本。这里的 "raw" 指的是这些数据只是普通文本，没有任何标注信息。这一步被称之为**预训练**，旨在创建一个初始的预训练 LLM，通常称为基础模型。
2. 该LLM会学习预测文本中的下一个单词。我们可以在优质的标注数据上对 LLM 进行进一步训练，这个过程称为微调。
	- 指令微调:标注数据集包含指令和答案对，例如用于翻译文本的查询及其正确翻译
	- 分类任务微调:比如与垃圾邮件和非垃圾邮件标签相关的电子邮件。


## Transformer 架构

大多数现代 LLM 基于 transformer 架构，这是一种深度神经网络架构，首次在 2017 年的论文《Attention Is All You Need》中提出。为了理解 LLM，我们需要简要回顾一下最初为机器翻译开发的原始 Transformer
![](assets/理解大语言模型/file-20260228204029117.png)

[^1]: 预训练的数据集已经学习好了语言模型的基础能力。
	而微调则是利用特定领域的数据来让模型适应某些特定的任务。
		全权重的微调
		冻结部分权重的微调：冻结部分权重的微调
